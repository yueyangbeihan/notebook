---


---

<blockquote>
<p>Written with <a href="https://stackedit.io/">StackEdit</a>.</p>
</blockquote>
<h1 id="大数据概述">大数据概述</h1>
<p>大数据思维导图(点击链可以展开详细)<br>
<img src="https://i.loli.net/2019/08/13/n7zpOUBKujb4tr1.png" alt="大数据 (1).png"><br>
(<a href="https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823">https://www.processon.com/view/link/5b9b6867e4b06fc64af4b823</a>)</p>
<ul>
<li>数据产生方式变革
<ul>
<li>运营式阶段：数据库使得数据管理复杂度降低，数据往往伴随着一定的运营活动产生记录，生产方式是被动的</li>
<li>用户原创内容阶段：Web2.0时代，用户原创成为标志，智能手机加速内容产生，数据产生方式是主动的</li>
<li>感知式系统阶段：感知系统广泛使用</li>
</ul>
</li>
<li>大数据发展历程</li>
</ul>

<table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>时间</strong></th>
<th><strong>内容</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>第一阶段：萌芽期</td>
<td>上世纪90年代至本世纪初</td>
<td>随着数据挖掘理论和数据库技术的逐步成熟，一批商业智能工具和知识管理技术开始被应用，如数据仓库、专家系统、知识管理系统等。</td>
</tr>
<tr>
<td>第二阶段：成熟期</td>
<td>本世纪前十年</td>
<td>Web2.0应用迅猛发展，非结构化数据大量产生，传统处理方法难以应对，带动了大数据技术的快速突破，大数据解决方案逐渐走向成熟，形成了并行计算与分布式系统两大核心技术，谷歌的GFS和MapReduce等大数据技术受到追捧，Hadoop平台开始大行其道</td>
</tr>
<tr>
<td>第三阶段：大规模应用期</td>
<td>2010年以后</td>
<td>大数据应用渗透各行各业，数据驱动决策，信息社会智能化程度大幅提高</td>
</tr>
</tbody>
</table><ul>
<li>大数据概念
<ul>
<li>大量化 Volume</li>
<li>快速化 Velocity （1秒定律）</li>
<li>多样化 Variety</li>
<li>价值化  Value  价值密度低，商业价值高</li>
</ul>
</li>
<li>大数据影响
<ul>
<li>科学研究：先后经历了实验、理论、计算和数据四中范式<br>
<img src="https://i.loli.net/2019/08/13/aFXqhifzbmRLVGK.png" alt="图片1.png"></li>
<li>思维方面（摘自《大数据时代》）
<ul>
<li>全样儿非抽样</li>
<li>效率而非精确</li>
<li>相关而非因果</li>
</ul>
</li>
</ul>
</li>
<li>大数据应用
<ul>
<li>智能医疗研发</li>
<li>监控身体情况</li>
<li>研发智能汽车</li>
<li>实时掌控交通情况，改善日常生活</li>
<li>金融交易</li>
<li>业务流程优化</li>
</ul>
</li>
<li>大数据关键技术</li>
</ul>

<table>
<thead>
<tr>
<th><strong>技术层面</strong></th>
<th align="left"><strong>功能</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>数据采集</td>
<td align="left">利用ETL工具将分布的、异构数据源中的数据如关系数据、平面数据文件等，抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础；或者也可以把实时采集的数据作为流计算系统的输入，进行实时处理分析</td>
</tr>
<tr>
<td>数据存储和管理</td>
<td align="left">利用分布式文件系统、数据仓库、关系数据库、NoSQL数据库、云数据库等，实现对结构化、半结构化和非结构化海量数据的存储和管理</td>
</tr>
<tr>
<td>数据处理与分析</td>
<td align="left">利用分布式并行编程模型和计算框架，结合机器学习和数据挖掘算法，实现对海量数据的处理和分析；对分析结果进行可视化呈现，帮助人们更好地理解数据、分析数据</td>
</tr>
<tr>
<td>数据隐私和安全</td>
<td align="left">在从大数据中挖掘潜在的巨大商业价值和学术价值的同时，构建隐私数据保护体系和数据安全体系，有效保护个人隐私和数据安全</td>
</tr>
</tbody>
</table><ul>
<li>
<p>两大核心技术<br>
<img src="https://i.loli.net/2019/08/13/OYDRiAm1vBK2cjw.png" alt="图片2.png"></p>
</li>
<li>
<p>大数据计算模式</p>
</li>
</ul>

<table>
<thead>
<tr>
<th><strong>大数据计算模式</strong></th>
<th><strong>解决问题</strong></th>
<th><strong>代表产品</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>批处理计算</td>
<td>针对大规模数据的批量处理</td>
<td>MapReduce、Spark等</td>
</tr>
<tr>
<td>流计算</td>
<td>针对流数据的实时计算</td>
<td>Storm、S4、Flume、Streams、Puma、DStream、Super Mario、银河流数据处理平台等</td>
</tr>
<tr>
<td>图计算</td>
<td>针对大规模图结构数据的处理</td>
<td>Pregel、GraphX、Giraph、PowerGraph、Hama、GoldenOrb等</td>
</tr>
<tr>
<td>查询分析计算</td>
<td>大规模数据的存储管理和查询分析</td>
<td>Dremel、Hive、Cassandra、Impala等</td>
</tr>
</tbody>
</table><ul>
<li>大数据产业</li>
</ul>

<table>
<thead>
<tr>
<th align="center"><strong>产业链环节</strong></th>
<th><strong>包含内容</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">IT基础设施层</td>
<td>包括提供硬件、软件、网络等基础设施以及提供咨询、规划和系统集成服务的企业，比如，提供数据中心解决方案的IBM、惠普和戴尔等，提供存储解决方案的EMC，提供虚拟化管理软件的微软、思杰、SUN、Redhat等</td>
</tr>
<tr>
<td align="center">数据源层</td>
<td>大数据生态圈里的数据提供者，是生物大数据（生物信息学领域的各类研究机构）、交通大数据（交通主管部门）、医疗大数据（各大医院、体检机构）、政务大数据（政府部门）、电商大数据（淘宝、天猫、苏宁云商、京东等电商）、社交网络大数据（微博、微信、人人网等）、搜索引擎大数据（百度、谷歌等）等各种数据的来源</td>
</tr>
<tr>
<td align="center">数据管理层</td>
<td>包括数据抽取、转换、存储和管理等服务的各类企业或产品，比如分布式文件系统（如Hadoop的HDFS和谷歌的GFS）、ETL工具（Informatica、Datastage、Kettle等）、数据库和数据仓库（Oracle、MySQL、SQL Server、HBase、GreenPlum等）</td>
</tr>
<tr>
<td align="center">数据分析层</td>
<td>包括提供分布式计算、数据挖掘、统计分析等服务的各类企业或产品，比如，分布式计算框架MapReduce、统计分析软件SPSS和SAS、数据挖掘工具Weka、数据可视化工具Tableau、BI工具（MicroStrategy、Cognos、BO）等等</td>
</tr>
<tr>
<td align="center">数据平台层</td>
<td>包括提供数据分享平台、数据分析平台、数据租售平台等服务的企业或产品，比如阿里巴巴、谷歌、中国电信、百度等</td>
</tr>
<tr>
<td align="center">数据应用层</td>
<td>提供智能交通、智慧医疗、智能物流、智能电网等行业应用的企业、机构或政府部门，比如交通主管部门、各大医疗机构、菜鸟网络、国家电网等</td>
</tr>
</tbody>
</table><ul>
<li>大数据、云计算、物联网关系</li>
</ul>
<p><img src="https://i.loli.net/2019/08/13/LNPauHj28IFpZn6.jpg" alt="图片3.jpg"></p>
<h1 id="hadoop-概述（hadoop-2.0）">Hadoop 概述（Hadoop 2.0）</h1>
<p>Hadoop 是 Apache 基金会下的一个开源分布式计算平台，以 <strong><font color="red">HDFS 分布式文件系统</font></strong> 和 <strong><font color="red">MapReduce</font></strong> 分布式计算框架为核心，为用户提供底层细节透明的分布式基础设施。目前，Hadoop 是分析海量数据的首选工具。Hadoop 是一个可以更容易开发和并行处理大规模数据的分布式计算平台，它的主要特点是扩展能力强、成本低、高效率和可靠。目前，Hadoop 的用户已经从传统的互联网公司，扩展到了各个行业，并且得到越来越广泛的应用。它的优势包括：</p>
<ol>
<li>方便：Hadoop 可以运行在商业机器集群上，或者Amazon EC2 等云计算服务商</li>
<li>弹性：Hadoop 可以方便增加和减少集群节点</li>
<li>健壮：Hadoop 可以从容处理常见的硬件失效情况</li>
<li>简单：Hadoop 允许用户快速高效编写并行分布代码</li>
</ol>
<h2 id="hadoop-项目结构">Hadoop 项目结构</h2>
<p><img src="https://i.loli.net/2019/08/13/LEQbCB2q53mphVo.png" alt="hadoop项目结构.png"></p>

<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS</td>
<td>分布式文件系统</td>
</tr>
<tr>
<td>MapReduce</td>
<td>分布式并行编程模型</td>
</tr>
<tr>
<td>YARN</td>
<td>资源管理和调度器</td>
</tr>
<tr>
<td>Tez</td>
<td>运行在YARN之上的下一代Hadoop查询处理框架</td>
</tr>
<tr>
<td>Hive</td>
<td>Hadoop上的数据仓库</td>
</tr>
<tr>
<td>HBase</td>
<td>Hadoop上的非关系型的分布式数据库</td>
</tr>
<tr>
<td>Pig</td>
<td>一个基于Hadoop的大规模数据分析平台，提供类似SQL的查询语言Pig Latin</td>
</tr>
<tr>
<td>Sqoop</td>
<td>用于在Hadoop与传统数据库之间进行数据传递</td>
</tr>
<tr>
<td>Oozie</td>
<td>Hadoop上的工作流管理系统</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>提供分布式协调一致性服务</td>
</tr>
<tr>
<td>Storm</td>
<td>流计算框架</td>
</tr>
<tr>
<td>Flume</td>
<td>一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统</td>
</tr>
<tr>
<td>Ambari</td>
<td>Hadoop快速部署工具，支持Apache Hadoop集群的供应、管理和监控</td>
</tr>
<tr>
<td>Kafka</td>
<td>一种高吞吐量的分布式发布订阅消息系统，可以处理消费者规模的网站中的所有动作流数据</td>
</tr>
<tr>
<td>Spark</td>
<td>类似于Hadoop MapReduce的通用并行框架</td>
</tr>
</tbody>
</table><ul>
<li>HDFS有着高容错特点，并且设计用来部署在低廉的硬件之上，适合有着超量大数据集的应用程序</li>
<li>MapReduce：Hadoop编程模型，用于大规模数据及（大于1TB）的并行计算。MR是离线处理框架，由编程模型、运行时环境（JobTracker和TaskTracker）和数据处理引擎（MapTask和ReduceTask）三部分组成</li>
<li>HBase:基于列存储模型的分布式数据库，专用用于Hadoop档案系统上的资料库系统，采用Column-Oriented设计，不同于传统关系型数据库，没有资料表、Schema等规范，而是采用Key-Value形式的架构，采用多维度的对应关系建立类似于表格效果的资料架构。如此采用分布式存储方式，可以扩充到前台服务器，应付PB级资料处理</li>
<li>Hive：可用SQL语法存储Hadoop资料的工具。
<ul>
<li>Hive是建置在HDFS上的一套分散式资料仓储系统，可让使用者以惯用的SQL语法，来存取Hadoop档案中的大型资料集，例如可以使用Join、Group by、Order by等，而这个语法称为Hive QL。Hive 提供完整的 SQL 查询功能，可以将 SQL 语句转换为 MR 任务进行运行。不过，Hive QL和SQL并非完全相同，例如Hive就不支援Store Procedure、Trigger等功能。</li>
<li>Hive会将使用者输入的Hive QL指令编译成Java程序，再来存取HDFS档案系统上的资料，所以，执行效率依指令复杂度和处理的资料量而异，可能有数秒鐘，甚至是数分鐘的延迟。和HBase相比，Hive容易使用且弹性高，但执行速度较慢。不少资料库系统，都是透过先连结到Hive，才能与Hadoop整合。例如微软就是透过Hive ODBC驱动程序，将SQL指令转换成Hive QL，让Excel可以存取Hadoop上的资料。</li>
<li>在同一个Hadoop集群中，Hive可以存取HBase上的资料，将HBase上的资料对应成Hive内的一个表格</li>
</ul>
</li>
<li>Pig：基于Hadoop分析组件，Pig 为复杂的海量数据并行计算提供一个简易的操作和编程接口。它提供了一个Script语言Pig Latin，语法简单，类似可读性高的高阶Basic语言，可用来撰写MapReduce程序。Pig会自动将这些脚本程序转换，成为能在Hadoop中执行的MapReduce Java程序。因此，使用者即使不懂Java也能撰写出MapReduce。<br>
Zookeeper：是一个高效的可扩展的资源协调系统，存储和协调关键共享状态。它监控和协调 Hadoop 分散式运作的集中式服务，可提供各个服务器的配置和运作状态资讯，用於提供不同Hadoop系统角色之间的工作协调。
<ul>
<li>以HBase资料库为例，其中有两种服务器角色：Region服务器角色和Master服务器角色，系统会自动透过ZooKeeper监看Master服务器的状态，一旦Master的运作资讯消失，代表当机或网路断线，HBase就会选出另一台Region服务器成为Mater角色来负责管理工作。</li>
<li>可等同于etcd功能</li>
</ul>
</li>
</ul>
<h1 id="hadoop-分布式文件系统-hdfs">Hadoop 分布式文件系统-HDFS</h1>
<p>分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)<br>
<img src="https://i.loli.net/2019/08/13/tqh4cEsCudyDOPX.jpg" alt="图片1.jpg"></p>
<h2 id="hdfs要实现的目标如下：">HDFS要实现的目标如下：</h2>
<ul>
<li>兼容廉价的硬件设备</li>
<li>流数据读写</li>
<li>大数据集</li>
<li>简单的文件模型</li>
<li>强大的跨平台兼容性<br>
HDFS在实现以上特性同时，也使得自身有一些局限性，主要包括如下几个方面：</li>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<h2 id="块">块</h2>
<p>HDFS默认一个块64MB，一个文件被分成多个块，以块作为存储单位块的大小远远大于普通文件系统，可以最小化寻址开销<br>
HDFS采用抽象的块概念可以带来以下几个明显的好处：</p>
<ul>
<li>支持大规模文件存储：文件以块为单位进行存储，一个大规模文件可以被分拆成若干个文件块，不同的文件块可以被分发到不同的节点上，因此，一个文件的大小不会受到单个节点的存储容量的限制，可以远远大于网络中任意节点的存储容量</li>
<li>简化系统设计：首先，大大简化了存储管理，因为文件块大小是固定的，这样就可以很容易计算出一个节点可以存储多少文件块；其次，方便了元数据的管理，元数据不需要和文件块一起存储，可以由其他系统负责管理元数据</li>
<li>适合数据备份：每个文件块都可以冗余存储到多个节点上，大大提高了系统的容错性和可用性</li>
</ul>
<h2 id="hdfs主要组件的功能">HDFS主要组件的功能</h2>

<table>
<thead>
<tr>
<th align="left"><strong>NameNode</strong></th>
<th align="left"><strong>DataNode</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">存储元数据</td>
<td align="left">存储文件内容</td>
</tr>
<tr>
<td align="left">元数据保存在内存中</td>
<td align="left">文件内容保存在磁盘上</td>
</tr>
<tr>
<td align="left">保存文件，block，datanode之间的映射关系</td>
<td align="left">维护了block id 到datanode本地文件的映射关系</td>
</tr>
</tbody>
</table><h3 id="namenode-数据结构">NameNode 数据结构</h3>
<ul>
<li>在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog
<ul>
<li>FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据</li>
<li>操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作</li>
</ul>
</li>
<li>名称节点记录了每个文件中各个块所在的数据节点的位置信息<br>
<img src="https://i.loli.net/2019/08/13/m8GYhtLoaIpbq2d.jpg" alt="图片2.jpg"></li>
</ul>
<h4 id="fsimage文件">FsImage文件</h4>
<ul>
<li>FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据</li>
<li>FsImage文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而是由名称节点把这些映射信息保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的</li>
</ul>
<h4 id="名称节点启动">名称节点启动</h4>
<ul>
<li>在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</li>
<li>一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件</li>
<li>名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新</li>
</ul>
<h4 id="名称节点运行期间editlog不断变大问题">名称节点运行期间EditLog不断变大问题</h4>
<ul>
<li>在名称节点运行期间，HDFS的所有更新操作都是直接写到EditLog中，久而久之， EditLog文件将会变得很大</li>
<li>虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内HDFS系统处于安全模式，一直无法对外提供写操作，影响了用户的使用<br>
<strong>答案：SecondaryNameNode第二名称节点</strong></li>
</ul>
<h4 id="secondary-namenode-工作情况">Secondary Namenode 工作情况</h4>
<p><img src="https://i.loli.net/2019/08/13/c8lQmqSNioyRFxM.png" alt="图片3.png"></p>
<ol>
<li>SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</li>
<li>SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；</li>
<li>SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</li>
<li>SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上</li>
<li>NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小了</li>
</ol>
<h3 id="datanode">DataNode</h3>
<ul>
<li>数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的快的列表</li>
<li>每个数据节点中的数据会被保存在各自节点的本地linux文件系统中</li>
</ul>
<h3 id="fdhs体系结构">FDHS体系结构</h3>
<p>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（NameNode）和若干个数据节点（DataNode）（如图3-4所示）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的<br>
<img src="https://i.loli.net/2019/08/13/WG3cMdAf8KLiSHe.jpg" alt="图片4.jpg"></p>

